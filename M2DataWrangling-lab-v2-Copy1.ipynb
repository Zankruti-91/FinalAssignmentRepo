{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...           0.00   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1           0.00           0.00           0.00            0.00   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1            0.00                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "                           Data Type  Non-Null Count  Null Count  \\\n",
      "AINextMuch less integrated    object            1148       64289   \n",
      "AINextLess integrated         object            2355       63082   \n",
      "AINextNo change               object           12498       52939   \n",
      "AINextMuch more integrated    object           13438       51999   \n",
      "EmbeddedAdmired               object           16733       48704   \n",
      "...                              ...             ...         ...   \n",
      "MainBranch                    object           65437           0   \n",
      "Age                           object           65437           0   \n",
      "Employment                    object           65437           0   \n",
      "Check                         object           65437           0   \n",
      "ResponseId                     int64           65437           0   \n",
      "\n",
      "                            Null Percentage  \n",
      "AINextMuch less integrated            98.25  \n",
      "AINextLess integrated                 96.40  \n",
      "AINextNo change                       80.90  \n",
      "AINextMuch more integrated            79.46  \n",
      "EmbeddedAdmired                       74.43  \n",
      "...                                     ...  \n",
      "MainBranch                             0.00  \n",
      "Age                                    0.00  \n",
      "Employment                             0.00  \n",
      "Check                                  0.00  \n",
      "ResponseId                             0.00  \n",
      "\n",
      "[114 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "summary = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null Percentage': (df.isnull().mean() * 100).round(2)\n",
    "})\n",
    "print(\"Dataset Summary:\")\n",
    "print(summary.sort_values('Null Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns Statistics:\n",
      "                        count  \\\n",
      "ResponseId          65,437.00   \n",
      "CompTotal           33,740.00   \n",
      "WorkExp             29,658.00   \n",
      "JobSatPoints_1      29,324.00   \n",
      "JobSatPoints_4      29,393.00   \n",
      "JobSatPoints_5      29,411.00   \n",
      "JobSatPoints_6      29,450.00   \n",
      "JobSatPoints_7      29,448.00   \n",
      "JobSatPoints_8      29,456.00   \n",
      "JobSatPoints_9      29,456.00   \n",
      "JobSatPoints_10     29,450.00   \n",
      "JobSatPoints_11     29,445.00   \n",
      "ConvertedCompYearly 23,435.00   \n",
      "JobSat              29,126.00   \n",
      "\n",
      "                                                                  mean  \\\n",
      "ResponseId                                                   32,719.00   \n",
      "CompTotal           29,638,411,381,149,976,434,844,996,221,255,135,...   \n",
      "WorkExp                                                          11.47   \n",
      "JobSatPoints_1                                                   18.58   \n",
      "JobSatPoints_4                                                    7.52   \n",
      "JobSatPoints_5                                                   10.06   \n",
      "JobSatPoints_6                                                   24.34   \n",
      "JobSatPoints_7                                                   22.97   \n",
      "JobSatPoints_8                                                   20.28   \n",
      "JobSatPoints_9                                                   16.17   \n",
      "JobSatPoints_10                                                  10.96   \n",
      "JobSatPoints_11                                                   9.95   \n",
      "ConvertedCompYearly                                          86,155.29   \n",
      "JobSat                                                            6.94   \n",
      "\n",
      "                                                                   std  min  \\\n",
      "ResponseId                                                   18,890.18 1.00   \n",
      "CompTotal           5,444,117,135,142,297,852,662,284,923,089,891,0... 0.00   \n",
      "WorkExp                                                           9.17 0.00   \n",
      "JobSatPoints_1                                                   25.97 0.00   \n",
      "JobSatPoints_4                                                   18.42 0.00   \n",
      "JobSatPoints_5                                                   21.83 0.00   \n",
      "JobSatPoints_6                                                   27.09 0.00   \n",
      "JobSatPoints_7                                                   27.02 0.00   \n",
      "JobSatPoints_8                                                   26.11 0.00   \n",
      "JobSatPoints_9                                                   24.85 0.00   \n",
      "JobSatPoints_10                                                  22.91 0.00   \n",
      "JobSatPoints_11                                                  21.78 0.00   \n",
      "ConvertedCompYearly                                         186,756.97 1.00   \n",
      "JobSat                                                            2.09 0.00   \n",
      "\n",
      "                           5%        50%          95%  \\\n",
      "ResponseId           3,272.80  32,719.00    62,165.20   \n",
      "CompTotal           18,000.00 110,000.00 3,600,000.00   \n",
      "WorkExp                  1.00       9.00        30.00   \n",
      "JobSatPoints_1           0.00      10.00        80.00   \n",
      "JobSatPoints_4           0.00       0.00        50.00   \n",
      "JobSatPoints_5           0.00       0.00        70.00   \n",
      "JobSatPoints_6           0.00      20.00        90.00   \n",
      "JobSatPoints_7           0.00      15.00        90.00   \n",
      "JobSatPoints_8           0.00      10.00        90.00   \n",
      "JobSatPoints_9           0.00       5.00        80.00   \n",
      "JobSatPoints_10          0.00       0.00        80.00   \n",
      "JobSatPoints_11          0.00       0.00        70.00   \n",
      "ConvertedCompYearly  3,497.00  65,000.00   210,000.00   \n",
      "JobSat                   3.00       7.00        10.00   \n",
      "\n",
      "                                                                   max  \\\n",
      "ResponseId                                                   65,437.00   \n",
      "CompTotal           1,000,000,000,000,000,162,545,277,246,339,097,2...   \n",
      "WorkExp                                                          50.00   \n",
      "JobSatPoints_1                                                  100.00   \n",
      "JobSatPoints_4                                                  100.00   \n",
      "JobSatPoints_5                                                  100.00   \n",
      "JobSatPoints_6                                                  100.00   \n",
      "JobSatPoints_7                                                  100.00   \n",
      "JobSatPoints_8                                                  100.00   \n",
      "JobSatPoints_9                                                  100.00   \n",
      "JobSatPoints_10                                                 100.00   \n",
      "JobSatPoints_11                                                 100.00   \n",
      "ConvertedCompYearly                                      16,256,603.00   \n",
      "JobSat                                                           10.00   \n",
      "\n",
      "                           IQR  \\\n",
      "ResponseId           32,718.00   \n",
      "CompTotal           190,000.00   \n",
      "WorkExp                  12.00   \n",
      "JobSatPoints_1           22.00   \n",
      "JobSatPoints_4            5.00   \n",
      "JobSatPoints_5           10.00   \n",
      "JobSatPoints_6           30.00   \n",
      "JobSatPoints_7           30.00   \n",
      "JobSatPoints_8           25.00   \n",
      "JobSatPoints_9           20.00   \n",
      "JobSatPoints_10          10.00   \n",
      "JobSatPoints_11          10.00   \n",
      "ConvertedCompYearly  75,259.50   \n",
      "JobSat                    2.00   \n",
      "\n",
      "                                                                 range  \\\n",
      "ResponseId                                                   65,436.00   \n",
      "CompTotal           1,000,000,000,000,000,162,545,277,246,339,097,2...   \n",
      "WorkExp                                                          50.00   \n",
      "JobSatPoints_1                                                  100.00   \n",
      "JobSatPoints_4                                                  100.00   \n",
      "JobSatPoints_5                                                  100.00   \n",
      "JobSatPoints_6                                                  100.00   \n",
      "JobSatPoints_7                                                  100.00   \n",
      "JobSatPoints_8                                                  100.00   \n",
      "JobSatPoints_9                                                  100.00   \n",
      "JobSatPoints_10                                                 100.00   \n",
      "JobSatPoints_11                                                 100.00   \n",
      "ConvertedCompYearly                                      16,256,602.00   \n",
      "JobSat                                                           10.00   \n",
      "\n",
      "                     skewness  kurtosis  missing  missing_pct  \n",
      "ResponseId               0.00     -1.20        0         0.00  \n",
      "CompTotal                 NaN       NaN    31697        48.44  \n",
      "WorkExp                  1.24      1.36    35779        54.68  \n",
      "JobSatPoints_1           1.72      2.07    36113        55.19  \n",
      "JobSatPoints_4           3.38     11.64    36044        55.08  \n",
      "JobSatPoints_5           2.76      6.90    36026        55.05  \n",
      "JobSatPoints_6           1.39      1.12    35987        54.99  \n",
      "JobSatPoints_7           1.52      1.44    35989        55.00  \n",
      "JobSatPoints_8           1.67      2.03    35981        54.99  \n",
      "JobSatPoints_9           2.00      3.21    35981        54.99  \n",
      "JobSatPoints_10          2.64      6.14    35987        54.99  \n",
      "JobSatPoints_11          2.78      7.03    35992        55.00  \n",
      "ConvertedCompYearly     52.92  3,950.78    42002        64.19  \n",
      "JobSat                  -1.00      0.95    36311        55.49  \n"
     ]
    }
   ],
   "source": [
    "# 1. Select numerical columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# 2. Safe calculation functions\n",
    "def safe_skew(x):\n",
    "    with np.errstate(all='ignore'):\n",
    "        return x.skew()\n",
    "\n",
    "def safe_kurt(x):  # Defined as safe_kurt\n",
    "    with np.errstate(all='ignore'):\n",
    "        return x.kurtosis()\n",
    "\n",
    "# 3. Generate statistics\n",
    "stats = df[num_cols].describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]).T\n",
    "stats['skewness'] = df[num_cols].apply(safe_skew)\n",
    "stats['kurtosis'] = df[num_cols].apply(safe_kurt)  # Corrected to use safe_kurt\n",
    "\n",
    "# 4. Add additional metrics\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "stats['range'] = stats['max'] - stats['min']\n",
    "stats['missing'] = df[num_cols].isnull().sum()\n",
    "stats['missing_pct'] = (df[num_cols].isnull().mean() * 100).round(2)\n",
    "\n",
    "# Format output\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "print(\"Numerical Columns Statistics:\")\n",
    "print(stats[['count', 'mean', 'std', 'min', '5%', '50%', '95%', 'max', \n",
    "             'IQR', 'range', 'skewness', 'kurtosis', 'missing', 'missing_pct']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Value Counts:\n",
      "Country\n",
      "United States of America                                11095\n",
      "NaN                                                      6507\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "France                                                   2110\n",
      "Canada                                                   2104\n",
      "Poland                                                   1534\n",
      "Netherlands                                              1449\n",
      "Brazil                                                   1375\n",
      "Italy                                                    1341\n",
      "Australia                                                1260\n",
      "Spain                                                    1123\n",
      "Sweden                                                   1016\n",
      "Russian Federation                                        925\n",
      "Switzerland                                               876\n",
      "Austria                                                   791\n",
      "Czech Republic                                            714\n",
      "Israel                                                    604\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Potential Issues:\n",
      "- Mixed case entries:No\n",
      "- Irrelevant placeholders:0 entries\n",
      "- Unexpected values: 51774 entries\n",
      "Sample unexpected values: ['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Norway'\n",
      " 'Uzbekistan' 'Serbia']\n"
     ]
    }
   ],
   "source": [
    "#Analyse 'Country' column\n",
    "country_counts = df['Country'].value_counts(dropna=False)\n",
    "\n",
    "print(\"Country Value Counts:\")\n",
    "print(country_counts.head(20)) #top 20 most frequent entries\n",
    "#Identify potential inconsistencies\n",
    "print(\"\\n Potential Issues:\")\n",
    "#Misex entries\n",
    "mixed_case = df[\"Country\"].str.islower().sum()>0\n",
    "print(f\"- Mixed case entries:{'Yes' if mixed_case else 'No'}\")\n",
    "\n",
    "#Irrelevant/placeholder entries\n",
    "irrelevant = df['Country'].str.contains('N/A|unknown|select|test', case=False, na=False).sum()\n",
    "print(f\"- Irrelevant placeholders:{irrelevant} entries\")\n",
    "valid_countries = ['USA','Canada','UK','India','China','Pakistan']\n",
    "unexpected = ~df['Country'].isin(valid_countries) & df['Country'].notna()\n",
    "print(f\"- Unexpected values: {unexpected.sum()} entries\")\n",
    "print(\"Sample unexpected values:\", df.loc[unexpected, 'Country'].unique()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map = {\n",
    "    # Case variations\n",
    "    'usa': 'USA',\n",
    "    'Usa': 'USA',\n",
    "    'u.s.a': 'USA',\n",
    "    'america': 'USA',\n",
    "    \n",
    "    # Common abbreviations\n",
    "    'uk': 'UK',\n",
    "    'u.k.': 'UK',\n",
    "    'united kingdom': 'UK',\n",
    "    \n",
    "    # Misspellings\n",
    "    'canada': 'Canada',\n",
    "    'cananda': 'Canada',\n",
    "    \n",
    "    # Custom rules\n",
    "    'unknown': None,\n",
    "    'n/a': None\n",
    "}\n",
    "\n",
    "df['Country'] = (df['Country'].str.strip().str.title().replace(country_map).where(df['Country'].notna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edlevel_map = {\n",
    "    'bachelors': 'Bachelor’s degree',\n",
    "    'bs': 'Bachelor’s degree',\n",
    "    'ba': 'Bachelor’s degree',\n",
    "    'masters': 'Master’s degree',\n",
    "    'ms': 'Master’s degree',\n",
    "    'phd': 'Doctoral degree',\n",
    "    'doctoral': 'Doctoral degree',\n",
    "    'high school': 'Secondary school',\n",
    "    'some college': 'Some college',\n",
    "    'college': 'Some college'\n",
    "}\n",
    "\n",
    "df['EdLevel'] = (df['EdLevel'].str.strip().str.title().replace(edlevel_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column(series, mapping):\n",
    "    return(series.str.strip().str.title().replace(mapping).where(series.notna()))\n",
    "\n",
    "df['Country'] = standardize_column(df['Country'], country_map)\n",
    "df['EdLevel'] = standardize_column(df['EdLevel'], edlevel_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized Country Values:\n",
      "Country\n",
      "United States Of America                                11095\n",
      "NaN                                                      6507\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom Of Great Britain And Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "France                                                   2110\n",
      "Canada                                                   2104\n",
      "Poland                                                   1534\n",
      "Netherlands                                              1449\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Standardized Education Levels:\n",
      "EdLevel\n",
      "Bachelor’S Degree (B.A., B.S., B.Eng., Etc.)                                          24942\n",
      "Master’S Degree (M.A., M.S., M.Eng., Mba, Etc.)                                       15557\n",
      "Some College/University Study Without Earning A Degree                                 7651\n",
      "Secondary School (E.G. American High School, German Realschule Or Gymnasium, Etc.)     5793\n",
      "NaN                                                                                    4653\n",
      "Professional Degree (Jd, Md, Ph.D, Ed.D, Etc.)                                         2970\n",
      "Associate Degree (A.A., A.S., Etc.)                                                    1793\n",
      "Primary/Elementary School                                                              1146\n",
      "Something Else                                                                          932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStandardized Country Values:\")\n",
    "print(df['Country'].value_counts(dropna=False).head(10))\n",
    "\n",
    "print(\"\\nStandardized Education Levels:\")\n",
    "print(df['EdLevel'].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-standard countries: 43000\n",
      "Sample non-standard: ['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Norway'\n",
      " 'Uzbekistan' 'Serbia']\n"
     ]
    }
   ],
   "source": [
    "#Flag remaining non-standard values\n",
    "valid_countries = ['USA',\n",
    "    'UK',\n",
    "    'Canada',\n",
    "    'India',\n",
    "    'China',\n",
    "    'Pakistan',\n",
    "    'Germany',\n",
    "    'France',\n",
    "    'Japan',\n",
    "    'Australia',\n",
    "    'Brazil',\n",
    "    'South Africa',\n",
    "    'Nigeria',\n",
    "    'Russia',\n",
    "    'South Korea',\n",
    "    'Singapore',\n",
    "    'Netherlands',\n",
    "    'Spain',\n",
    "    'Italy',\n",
    "    'Mexico']\n",
    "df['Country_IsStandard'] = df['Country'].isin(valid_countries)\n",
    "print(f\"\\nNon-standard countries: {len(df) - df['Country_IsStandard'].sum()}\")\n",
    "print(\"Sample non-standard:\", \n",
    "      df.loc[~df['Country_IsStandard'], 'Country'].dropna().unique()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Employment  emp_employed_full-time  emp_employed_part-time  \\\n",
      "0      Employed, full-time                       1                       0   \n",
      "1      Employed, full-time                       1                       0   \n",
      "2      Employed, full-time                       1                       0   \n",
      "3       Student, full-time                       0                       0   \n",
      "4       Student, full-time                       0                       0   \n",
      "...                    ...                     ...                     ...   \n",
      "65432  Employed, full-time                       1                       0   \n",
      "65433  Employed, full-time                       1                       0   \n",
      "65434  Employed, full-time                       1                       0   \n",
      "65435  Employed, full-time                       1                       0   \n",
      "65436   Student, full-time                       0                       0   \n",
      "\n",
      "       emp_i_prefer_not_to_say  \\\n",
      "0                            0   \n",
      "1                            0   \n",
      "2                            0   \n",
      "3                            0   \n",
      "4                            0   \n",
      "...                        ...   \n",
      "65432                        0   \n",
      "65433                        0   \n",
      "65434                        0   \n",
      "65435                        0   \n",
      "65436                        0   \n",
      "\n",
      "       emp_independent_contractor_freelancer_or_self-employed  \\\n",
      "0                                                      0        \n",
      "1                                                      0        \n",
      "2                                                      0        \n",
      "3                                                      0        \n",
      "4                                                      0        \n",
      "...                                                  ...        \n",
      "65432                                                  0        \n",
      "65433                                                  0        \n",
      "65434                                                  0        \n",
      "65435                                                  0        \n",
      "65436                                                  0        \n",
      "\n",
      "       emp_not_employed_and_not_looking_for_work  \\\n",
      "0                                              0   \n",
      "1                                              0   \n",
      "2                                              0   \n",
      "3                                              0   \n",
      "4                                              0   \n",
      "...                                          ...   \n",
      "65432                                          0   \n",
      "65433                                          0   \n",
      "65434                                          0   \n",
      "65435                                          0   \n",
      "65436                                          0   \n",
      "\n",
      "       emp_not_employed_but_looking_for_work  emp_retired  \\\n",
      "0                                          0            0   \n",
      "1                                          0            0   \n",
      "2                                          0            0   \n",
      "3                                          0            0   \n",
      "4                                          0            0   \n",
      "...                                      ...          ...   \n",
      "65432                                      0            0   \n",
      "65433                                      0            0   \n",
      "65434                                      0            0   \n",
      "65435                                      0            0   \n",
      "65436                                      0            0   \n",
      "\n",
      "       emp_student_full-time  emp_student_part-time  \n",
      "0                          0                      0  \n",
      "1                          0                      0  \n",
      "2                          0                      0  \n",
      "3                          1                      0  \n",
      "4                          1                      0  \n",
      "...                      ...                    ...  \n",
      "65432                      0                      0  \n",
      "65433                      0                      0  \n",
      "65434                      0                      0  \n",
      "65435                      0                      0  \n",
      "65436                      1                      0  \n",
      "\n",
      "[65437 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Split mulitple employment status\n",
    "employment_split = df['Employment'].str.split(';')\n",
    "#get all unique employment categories\n",
    "all_categories = set()\n",
    "for sublist in employment_split.dropna():\n",
    "    all_categories.update(sublist)\n",
    "unique_categories = sorted(all_categories)\\\n",
    "#Create one-hot encoded columns\n",
    "for category in unique_categories:\n",
    "    #Clean category name for column naming\n",
    "    col_name = f\"emp_{category.lower().replace(',','').replace(' ','_')}\"\n",
    "    df[col_name] = df['Employment'].apply(\n",
    "        lambda x: 1 if pd.notna(x) and category in x.split(';') else 0\n",
    "    )\n",
    "# Clean up column names\n",
    "df.columns = df.columns.str.replace(',','')\n",
    "#Display results\n",
    "print(df[['Employment'] + [col for col in df.columns if col.startswith('emp_')]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with Highest Missing Values:\n",
      "                               Missing_Count  Missing_Percentage\n",
      "AINextMuch less integrated             64289               98.25\n",
      "AINextLess integrated                  63082               96.40\n",
      "AINextNo change                        52939               80.90\n",
      "AINextMuch more integrated             51999               79.46\n",
      "EmbeddedAdmired                        48704               74.43\n",
      "EmbeddedWantToWorkWith                 47837               73.10\n",
      "EmbeddedHaveWorkedWith                 43223               66.05\n",
      "ConvertedCompYearly                    42002               64.19\n",
      "AIToolNot interested in Using          41023               62.69\n",
      "AINextMore integrated                  41009               62.67\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing values and sort\n",
    "missing_stats = (\n",
    "    df.isnull().sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(name='Missing_Count')\n",
    "    .assign(Missing_Percentage=lambda x: (x['Missing_Count']/ len(df)*100))\n",
    ")\n",
    "\n",
    "print(\"Columns with Highest Missing Values:\")\n",
    "print(missing_stats[missing_stats['Missing_Count'] > 0].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed 0 missing values in WorkExp with median value: 9.00\n",
      "Imputed 0 missing values in JobSatPoints_1 with median value: 10.00\n",
      "Imputed 0 missing values in JobSatPoints_4 with median value: 0.00\n",
      "Imputed 0 missing values in JobSatPoints_5 with median value: 0.00\n",
      "Imputed 0 missing values in JobSatPoints_6 with median value: 20.00\n",
      "Imputed 0 missing values in JobSatPoints_7 with median value: 15.00\n",
      "Imputed 0 missing values in JobSatPoints_8 with median value: 10.00\n",
      "Imputed 0 missing values in JobSatPoints_9 with median value: 5.00\n",
      "Imputed 0 missing values in JobSatPoints_10 with median value: 0.00\n",
      "Imputed 0 missing values in JobSatPoints_11 with median value: 0.00\n",
      "Imputed 0 missing values in ConvertedCompYearly with median value: 65,000.00\n",
      "Imputed 0 missing values in JobSat with median value: 7.00\n"
     ]
    }
   ],
   "source": [
    "#Select numerical columns\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "#Choose stratergy - Mean or Median\n",
    "STRATERGY = 'median'\n",
    "\n",
    "for col in num_cols:\n",
    "    if df[col].isnull().sum() > 0: #Only process columns with missing values\n",
    "        if STRATERGY == 'median':\n",
    "            fill_value = df[col].median()\n",
    "        else:\n",
    "            fill_value = df[col].mean()\n",
    "        df[col] = df[col].fillna(fill_value)\n",
    "        print(f\"Imputed {df[col].isnull().sum()} missing values in {col} with {STRATERGY} value: {fill_value:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imupted 0 missing values in 'RemoteWork' with mode: 'Hybrid (some remote, some in-person)'\n",
      "Imupted 0 missing values in 'CodingActivities' with mode: 'Hobby'\n",
      "Imupted 0 missing values in 'EdLevel' with mode: 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      "Imupted 0 missing values in 'LearnCode' with mode: 'Other online resources (e.g., videos, blogs, forum, online community)'\n",
      "Imupted 0 missing values in 'LearnCodeOnline' with mode: 'Technical documentation;Blogs;Written Tutorials;Stack Overflow'\n",
      "Imupted 0 missing values in 'TechDoc' with mode: 'API document(s) and/or SDK document(s);User guides or README files found in the source repository;Traditional public search engine'\n",
      "Imupted 0 missing values in 'YearsCode' with mode: '10'\n",
      "Imupted 0 missing values in 'YearsCodePro' with mode: '2'\n",
      "Imupted 0 missing values in 'DevType' with mode: 'Developer, full-stack'\n",
      "Imupted 0 missing values in 'OrgSize' with mode: '20 to 99 employees'\n",
      "Imupted 0 missing values in 'PurchaseInfluence' with mode: 'I have some influence'\n",
      "Imupted 0 missing values in 'BuyNewTool' with mode: 'Start a free trial;Ask developers I know/work with;Visit developer communities like Stack Overflow'\n",
      "Imupted 0 missing values in 'BuildvsBuy' with mode: 'Is ready-to-go but also customizable for growth and targeted use cases'\n",
      "Imupted 0 missing values in 'TechEndorse' with mode: 'APIs;Customization;Reputation for quality and excellence'\n",
      "Imupted 0 missing values in 'Country' with mode: 'United States of America'\n",
      "Imupted 0 missing values in 'Currency' with mode: 'EUR European Euro'\n",
      "Imupted 0 missing values in 'LanguageHaveWorkedWith' with mode: 'HTML/CSS;JavaScript;TypeScript'\n",
      "Imupted 0 missing values in 'LanguageWantToWorkWith' with mode: 'Python'\n",
      "Imupted 0 missing values in 'LanguageAdmired' with mode: 'Python'\n",
      "Imupted 0 missing values in 'DatabaseHaveWorkedWith' with mode: 'PostgreSQL'\n",
      "Imupted 0 missing values in 'DatabaseWantToWorkWith' with mode: 'PostgreSQL'\n",
      "Imupted 0 missing values in 'DatabaseAdmired' with mode: 'PostgreSQL'\n",
      "Imupted 0 missing values in 'PlatformHaveWorkedWith' with mode: 'Amazon Web Services (AWS)'\n",
      "Imupted 0 missing values in 'PlatformWantToWorkWith' with mode: 'Amazon Web Services (AWS)'\n",
      "Imupted 0 missing values in 'PlatformAdmired' with mode: 'Amazon Web Services (AWS)'\n",
      "Imupted 0 missing values in 'WebframeHaveWorkedWith' with mode: 'React'\n",
      "Imupted 0 missing values in 'WebframeWantToWorkWith' with mode: 'React'\n",
      "Imupted 0 missing values in 'WebframeAdmired' with mode: 'React'\n",
      "Imupted 0 missing values in 'EmbeddedHaveWorkedWith' with mode: 'Rasberry Pi'\n",
      "Imupted 0 missing values in 'EmbeddedWantToWorkWith' with mode: 'Rasberry Pi'\n",
      "Imupted 0 missing values in 'EmbeddedAdmired' with mode: 'Rasberry Pi'\n",
      "Imupted 0 missing values in 'MiscTechHaveWorkedWith' with mode: '.NET (5+) '\n",
      "Imupted 0 missing values in 'MiscTechWantToWorkWith' with mode: '.NET (5+) '\n",
      "Imupted 0 missing values in 'MiscTechAdmired' with mode: '.NET (5+) '\n",
      "Imupted 0 missing values in 'ToolsTechHaveWorkedWith' with mode: 'Docker'\n",
      "Imupted 0 missing values in 'ToolsTechWantToWorkWith' with mode: 'Docker'\n",
      "Imupted 0 missing values in 'ToolsTechAdmired' with mode: 'Docker'\n",
      "Imupted 0 missing values in 'NEWCollabToolsHaveWorkedWith' with mode: 'Visual Studio Code'\n",
      "Imupted 0 missing values in 'NEWCollabToolsWantToWorkWith' with mode: 'Visual Studio Code'\n",
      "Imupted 0 missing values in 'NEWCollabToolsAdmired' with mode: 'Visual Studio Code'\n",
      "Imupted 0 missing values in 'OpSysPersonal use' with mode: 'Windows'\n",
      "Imupted 0 missing values in 'OpSysProfessional use' with mode: 'Windows'\n",
      "Imupted 0 missing values in 'OfficeStackAsyncHaveWorkedWith' with mode: 'Jira'\n",
      "Imupted 0 missing values in 'OfficeStackAsyncWantToWorkWith' with mode: 'Jira'\n",
      "Imupted 0 missing values in 'OfficeStackAsyncAdmired' with mode: 'Jira'\n",
      "Imupted 0 missing values in 'OfficeStackSyncHaveWorkedWith' with mode: 'Microsoft Teams'\n",
      "Imupted 0 missing values in 'OfficeStackSyncWantToWorkWith' with mode: 'Microsoft Teams'\n",
      "Imupted 0 missing values in 'OfficeStackSyncAdmired' with mode: 'Microsoft Teams'\n",
      "Imupted 0 missing values in 'AISearchDevHaveWorkedWith' with mode: 'ChatGPT'\n",
      "Imupted 0 missing values in 'AISearchDevWantToWorkWith' with mode: 'ChatGPT'\n",
      "Imupted 0 missing values in 'AISearchDevAdmired' with mode: 'ChatGPT'\n",
      "Imupted 0 missing values in 'NEWSOSites' with mode: 'Stack Overflow;Stack Exchange'\n",
      "Imupted 0 missing values in 'SOVisitFreq' with mode: 'A few times per week'\n",
      "Imupted 0 missing values in 'SOAccount' with mode: 'Yes'\n",
      "Imupted 0 missing values in 'SOPartFreq' with mode: 'Less than once per month or monthly'\n",
      "Imupted 0 missing values in 'SOHow' with mode: 'Quickly finding code solutions;Finding reliable guidance from community-vetted answers'\n",
      "Imupted 0 missing values in 'SOComm' with mode: 'No, not really'\n",
      "Imupted 0 missing values in 'AISelect' with mode: 'Yes'\n",
      "Imupted 0 missing values in 'AISent' with mode: 'Favorable'\n",
      "Imupted 0 missing values in 'AIBen' with mode: 'Increase productivity;Greater efficiency;Speed up learning'\n",
      "Imupted 0 missing values in 'AIAcc' with mode: 'Somewhat trust'\n",
      "Imupted 0 missing values in 'AIComplex' with mode: 'Good, but not great at handling complex tasks'\n",
      "Imupted 0 missing values in 'AIToolCurrently Using' with mode: 'Writing code;Debugging and getting help;Search for answers'\n",
      "Imupted 0 missing values in 'AIToolInterested in Using' with mode: 'Learning about a codebase'\n",
      "Imupted 0 missing values in 'AIToolNot interested in Using' with mode: 'Project planning'\n",
      "Imupted 0 missing values in 'AINextMuch more integrated' with mode: 'Search for answers'\n",
      "Imupted 0 missing values in 'AINextNo change' with mode: 'Writing code'\n",
      "Imupted 0 missing values in 'AINextMore integrated' with mode: 'Writing code'\n",
      "Imupted 0 missing values in 'AINextLess integrated' with mode: 'Writing code'\n",
      "Imupted 0 missing values in 'AINextMuch less integrated' with mode: 'Writing code'\n",
      "Imupted 0 missing values in 'AIThreat' with mode: 'No'\n",
      "Imupted 0 missing values in 'AIEthics' with mode: 'Circulating misinformation or disinformation;Missing or incorrect attribution for sources of data;Biased results that do not represent diverse viewpoints'\n",
      "Imupted 0 missing values in 'AIChallenges' with mode: 'Don’t trust the output or answers;AI tools lack context of codebase,  internal architecture, and/or company knowledge'\n",
      "Imupted 0 missing values in 'TBranch' with mode: 'Yes'\n",
      "Imupted 0 missing values in 'ICorPM' with mode: 'Individual contributor'\n",
      "Imupted 0 missing values in 'Knowledge_1' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_2' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_3' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_4' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_5' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_6' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_7' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_8' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Knowledge_9' with mode: 'Agree'\n",
      "Imupted 0 missing values in 'Frequency_1' with mode: '1-2 times a week'\n",
      "Imupted 0 missing values in 'Frequency_2' with mode: '1-2 times a week'\n",
      "Imupted 0 missing values in 'Frequency_3' with mode: '1-2 times a week'\n",
      "Imupted 0 missing values in 'TimeSearching' with mode: '30-60 minutes a day'\n",
      "Imupted 0 missing values in 'TimeAnswering' with mode: '15-30 minutes a day'\n",
      "Imupted 0 missing values in 'Frustration' with mode: 'None of these'\n",
      "Imupted 0 missing values in 'ProfessionalTech' with mode: 'None of these'\n",
      "Imupted 0 missing values in 'ProfessionalCloud' with mode: 'Hybrid (on-prem and cloud)'\n",
      "Imupted 0 missing values in 'ProfessionalQuestion' with mode: 'Traditional public search engine'\n",
      "Imupted 0 missing values in 'Industry' with mode: 'Software Development'\n",
      "Imupted 0 missing values in 'SurveyLength' with mode: 'Appropriate in length'\n",
      "Imupted 0 missing values in 'SurveyEase' with mode: 'Easy'\n"
     ]
    }
   ],
   "source": [
    "#select categorail columns\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        #get most frequent values (mode)\n",
    "        mode_values = df[col].mode()[0]\n",
    "        #impute missing values\n",
    "        df[col] = df[col].fillna(mode_values)\n",
    "\n",
    "        print(f\"Imupted {df[col].isnull().sum()} missing values in '{col}' with mode: '{mode_values}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate min and max\n",
    "comp_min = df['ConvertedCompYearly'].min()\n",
    "comp_max = df['ConvertedCompYearly'].max()\n",
    "\n",
    "#Normalize in one operation\n",
    "df_normalized = df.assign(\n",
    "    ConvertedCompYearly_Normalized = lambda x: (x['ConvertedCompYearly'] - comp_min) / (comp_max - comp_min)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformation Summary:\n",
      "Original range: [1.00, 16,256,603.00]\n",
      "Log range: [0.00, 16.60]\n",
      "Skewness reduced from 87.71 to -4.38\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "# 1. Handle missing values\n",
    "comp_median = df['ConvertedCompYearly'].median()\n",
    "comp_clean = df['ConvertedCompYearly'].fillna(comp_median)\n",
    "\n",
    "# 2. Calculate offset for non-positive values\n",
    "min_comp = float(comp_clean.min())  # Convert to native Python float\n",
    "offset = 1 - min_comp if min_comp <= 0 else 0\n",
    "if offset > 0:\n",
    "    print(f\"Added offset: {offset:.2f}\")\n",
    "\n",
    "# 3. Perform log transformation\n",
    "log_values = np.log(comp_clean + offset)\n",
    "\n",
    "# 4. Create new DataFrame (memory-efficient)\n",
    "df = df.assign(\n",
    "    ConvertedCompYearly_Log=log_values\n",
    ")\n",
    "\n",
    "# 5. Verify results (using native Python floats for formatting)\n",
    "log_min = float(log_values.min())\n",
    "log_max = float(log_values.max())\n",
    "orig_min = float(comp_clean.min())\n",
    "orig_max = float(comp_clean.max())\n",
    "\n",
    "print(\"\\nTransformation Summary:\")\n",
    "print(f\"Original range: [{orig_min:,.2f}, {orig_max:,.2f}]\")\n",
    "print(f\"Log range: [{log_min:.2f}, {log_max:.2f}]\")\n",
    "print(f\"Skewness reduced from {skew(comp_clean):.2f} to {skew(log_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numeric\n",
    "df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "#create experiencelevel categories\n",
    "conditions = [\n",
    "    (df['YearsCodePro'].isna()),\n",
    "    (df['YearsCodePro'] <= 2),\n",
    "    (df['YearsCodePro'] <= 5),\n",
    "    (df['YearsCodePro'] <= 10),\n",
    "    (df['YearsCodePro'] > 10),\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'Unknown',\n",
    "    'Entry-level (0-2 years)',\n",
    "    'Mid-level (3-5 years)',\n",
    "    'Senior (6-10 years)',\n",
    "    'Expert (10+ years)'\n",
    "]\n",
    "\n",
    "df['ExperienceLevel'] = np.select(conditions, choices, default='Unknown')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
